{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for prediction can either collected from Kaggle or Poloniex. To make sure coherence, the column names for data collected from Poloniex are changed to match with Kaggleâ€™s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1612860000</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.472879</td>\n",
       "      <td>0.474271</td>\n",
       "      <td>0.474276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1612860300</td>\n",
       "      <td>0.474507</td>\n",
       "      <td>0.474178</td>\n",
       "      <td>0.474276</td>\n",
       "      <td>0.474451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1612860600</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>0.473067</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>0.473875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1612860900</td>\n",
       "      <td>0.473562</td>\n",
       "      <td>0.472824</td>\n",
       "      <td>0.473539</td>\n",
       "      <td>0.472931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1612861200</td>\n",
       "      <td>0.472445</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.472445</td>\n",
       "      <td>0.471600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp      High       Low      Open     Close\n",
       "0  1612860000  0.474300  0.472879  0.474271  0.474276\n",
       "1  1612860300  0.474507  0.474178  0.474276  0.474451\n",
       "2  1612860600  0.474141  0.473067  0.474141  0.473875\n",
       "3  1612860900  0.473562  0.472824  0.473539  0.472931\n",
       "4  1612861200  0.472445  0.471300  0.472445  0.471600"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Connect to poloniex's API\n",
    "url_0 = 'https://poloniex.com/public?command=returnChartData&currencyPair=USDT_XRP&start=1612860000&end=1618242600&period=300'\n",
    "\n",
    "url = [url_0]\n",
    "length = [17943]\n",
    "start = 1612860000\n",
    "end = 1621499700\n",
    "\n",
    "url_left = 'https://poloniex.com/public?command=returnChartData&currencyPair=USDT_XRP&start='\n",
    "url_mid = '&end='\n",
    "url_right = '&period=300'\n",
    "num = 28800\n",
    "\n",
    "# Get data. Poloniex website forbid large data request at one time.\n",
    "for i in range(18):\n",
    "    start -= 8640000 \n",
    "    end -= 8640000\n",
    "    url_cur = url_left + str(start) + url_mid + str(end) + url_right\n",
    "    url.append(url_cur)\n",
    "    length.append(28800)\n",
    "    num += 1\n",
    "\n",
    "# Change data request length, because some data are missing from poloniex.\n",
    "length[18] = 28794\n",
    "length[17] = 28766\n",
    "length[16] = 28764\n",
    "length[15] = 28799\n",
    "length[6] = 28796\n",
    "length[2] = 28799\n",
    "\n",
    "# Parse json returned from the API to Pandas DF\n",
    "openUrl = urlopen(url.pop())\n",
    "r = openUrl.read()\n",
    "openUrl.close()\n",
    "d = json.loads(r.decode())\n",
    "df = pd.DataFrame(d, index=[i for i in range(length.pop())], columns=['date','high','low','open','close'])\n",
    "\n",
    "# Rename data table\n",
    "original_columns=[u'date', u'high', u'low', u'open', u'close']\n",
    "new_columns = ['Timestamp', 'High', 'Low', 'Open', 'Close']\n",
    "df = df.loc[:,original_columns]\n",
    "df.columns = new_columns\n",
    "df.to_csv('data/ripple2016to2021.csv',index=None)\n",
    "\n",
    "for i in range(len(url)-1, -1, -1):\n",
    "    openUrl = urlopen(url[i])\n",
    "    r = openUrl.read()\n",
    "    openUrl.close()\n",
    "    d = json.loads(r.decode())\n",
    "    df = pd.DataFrame(d, index=[i for i in range(length[i])], columns=['date','high','low','open','close'])\n",
    "\n",
    "    df = df.loc[:,original_columns]\n",
    "    df.columns = new_columns\n",
    "    df.to_csv('data/ripple2016to2021.csv', mode='a', index=None, header=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collected from source needs to be parsed in order to send to the model for prediction. The PastSampler class is for splitting the data into a list of datas and labels. The input size (N) is 256, while the output size (K) is 16. Note that data collected from Poloniex was ticked on a 5 minute basis. This indicates that, if the input spans across 1280 minutes, the output covers over 80 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PastSampler:\n",
    "    '''\n",
    "    Forms training samples for predicting future values from past value\n",
    "    '''\n",
    "     \n",
    "    def __init__(self, N, K, sliding_window = True):\n",
    "        '''\n",
    "        Predict K future sample using N previous samples\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.sliding_window = sliding_window\n",
    " \n",
    "    def transform(self, A):\n",
    "        M = self.N + self.K     #Number of samples per row (sample + target)\n",
    "        #indexes\n",
    "        if self.sliding_window:\n",
    "            I = np.arange(M) + np.arange(A.shape[0] - M + 1).reshape(-1, 1)\n",
    "        else:\n",
    "            if A.shape[0]%M == 0:\n",
    "                I = np.arange(M)+np.arange(0,A.shape[0],M).reshape(-1,1)\n",
    "                \n",
    "            else:\n",
    "                I = np.arange(M)+np.arange(0,A.shape[0] -M,M).reshape(-1,1)\n",
    "            \n",
    "        B = A[I].reshape(-1, M * A.shape[1], A.shape[2])\n",
    "        ci = self.N * A.shape[1]    #Number of features per sample\n",
    "        return B[:, :ci], B[:, ci:] #Sample matrix, Target matrix\n",
    "\n",
    "# Data file path\n",
    "dfp = 'data/ripple2016to2021.csv'\n",
    "\n",
    "# Columns of price data to use\n",
    "columns = ['Close']\n",
    "df = pd.read_csv(dfp)\n",
    "time_stamps = df['Timestamp']\n",
    "df = df.loc[:,columns]\n",
    "original_df = pd.read_csv(dfp).loc[:,columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the PastSampler class, we apply it on the collected data. Since the original data ranges from 0 to over 60000, data scaling is needed to allow the neural network to understand the data easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='ripple2016to2021_close.h5'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Normalization\n",
    "for c in columns:\n",
    "    df[c] = scaler.fit_transform(df[c].values.reshape(-1,1))\n",
    "    \n",
    "# Features are input sample dimensions(channels)\n",
    "A = np.array(df)[:,None,:]\n",
    "original_A = np.array(original_df)[:,None,:]\n",
    "time_stamps = np.array(time_stamps)[:,None,None]\n",
    "\n",
    "# Make samples of temporal sequences of pricing data (channel)\n",
    "NPS, NFS = 256, 16         #Number of past and future samples\n",
    "ps = PastSampler(NPS, NFS, sliding_window=False)\n",
    "B, Y = ps.transform(A)\n",
    "input_times, output_times = ps.transform(time_stamps)\n",
    "original_B, original_Y = ps.transform(original_A)\n",
    "\n",
    "# Create h5 file.\n",
    "import h5py\n",
    "with h5py.File(file_name, 'w') as f:\n",
    "    f.create_dataset(\"inputs\", data = B)\n",
    "    f.create_dataset('outputs', data = Y)\n",
    "    f.create_dataset(\"input_times\", data = input_times)\n",
    "    f.create_dataset('output_times', data = output_times)\n",
    "    f.create_dataset(\"original_datas\", data=np.array(original_df))\n",
    "    f.create_dataset('original_inputs',data=original_B)\n",
    "    f.create_dataset('original_outputs',data=original_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}