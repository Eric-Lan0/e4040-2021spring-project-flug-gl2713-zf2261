{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for prediction can either collected from Kaggle or Poloniex. To make sure coherence, the column names for data collected from Poloniex are changed to match with Kaggleâ€™s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1612860000</td>\n",
       "      <td>1802.909884</td>\n",
       "      <td>1791.473678</td>\n",
       "      <td>1799.742687</td>\n",
       "      <td>1796.696858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1612860300</td>\n",
       "      <td>1800.208498</td>\n",
       "      <td>1794.929996</td>\n",
       "      <td>1796.607035</td>\n",
       "      <td>1800.208498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1612860600</td>\n",
       "      <td>1808.000000</td>\n",
       "      <td>1801.000000</td>\n",
       "      <td>1801.000000</td>\n",
       "      <td>1805.780944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1612860900</td>\n",
       "      <td>1806.652680</td>\n",
       "      <td>1799.728182</td>\n",
       "      <td>1806.652680</td>\n",
       "      <td>1801.462288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1612861200</td>\n",
       "      <td>1808.826969</td>\n",
       "      <td>1802.280236</td>\n",
       "      <td>1802.280236</td>\n",
       "      <td>1804.344718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp         High          Low         Open        Close\n",
       "0  1612860000  1802.909884  1791.473678  1799.742687  1796.696858\n",
       "1  1612860300  1800.208498  1794.929996  1796.607035  1800.208498\n",
       "2  1612860600  1808.000000  1801.000000  1801.000000  1805.780944\n",
       "3  1612860900  1806.652680  1799.728182  1806.652680  1801.462288\n",
       "4  1612861200  1808.826969  1802.280236  1802.280236  1804.344718"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# connect to poloniex's API\n",
    "url_0 = 'https://poloniex.com/public?command=returnChartData&currencyPair=USDT_ETH&start=1612860000&end=1618242600&period=300'\n",
    "\n",
    "url = [url_0]\n",
    "length = [17943]\n",
    "start = 1612860000\n",
    "end = 1621499700\n",
    "\n",
    "url_left = 'https://poloniex.com/public?command=returnChartData&currencyPair=USDT_ETH&start='\n",
    "url_mid = '&end='\n",
    "url_right = '&period=300'\n",
    "\n",
    "for i in range(18):\n",
    "    start -= 8640000 \n",
    "    end -= 8640000\n",
    "    url_cur = url_left + str(start) + url_mid + str(end) + url_right\n",
    "    url.append(url_cur)\n",
    "    length.append(28800)\n",
    "\n",
    "length[17] = 28798\n",
    "length[9] = 28799\n",
    "\n",
    "# parse json returned from the API to Pandas DF\n",
    "openUrl = urlopen(url.pop())\n",
    "r = openUrl.read()\n",
    "openUrl.close()\n",
    "d = json.loads(r.decode())\n",
    "df = pd.DataFrame(d, index=[i for i in range(length.pop())], columns=['date','high','low','open','close'])\n",
    "\n",
    "original_columns=[u'date', u'high', u'low', u'open', u'close']\n",
    "new_columns = ['Timestamp', 'High', 'Low', 'Open', 'Close']\n",
    "df = df.loc[:,original_columns]\n",
    "df.columns = new_columns\n",
    "df.to_csv('data/ethereum2016to2021.csv',index=None)\n",
    "\n",
    "for i in range(len(url)-1, -1, -1):\n",
    "    openUrl = urlopen(url[i])\n",
    "    r = openUrl.read()\n",
    "    openUrl.close()\n",
    "    d = json.loads(r.decode())\n",
    "    df = pd.DataFrame(d, index=[i for i in range(length[i])], columns=['date','high','low','open','close'])\n",
    "\n",
    "    df = df.loc[:,original_columns]\n",
    "    df.columns = new_columns\n",
    "    df.to_csv('data/ethereum2016to2021.csv', mode='a', index=None, header=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collected from source needs to be parsed in order to send to the model for prediction. The PastSampler class is for splitting the data into a list of datas and labels. The input size (N) is 256, while the output size (K) is 16. Note that data collected from Poloniex was ticked on a 5 minute basis. This indicates that, if the input spans across 1280 minutes, the output covers over 80 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PastSampler:\n",
    "    '''\n",
    "    Forms training samples for predicting future values from past value\n",
    "    '''\n",
    "     \n",
    "    def __init__(self, N, K, sliding_window = True):\n",
    "        '''\n",
    "        Predict K future sample using N previous samples\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.sliding_window = sliding_window\n",
    " \n",
    "    def transform(self, A):\n",
    "        M = self.N + self.K     #Number of samples per row (sample + target)\n",
    "        #indexes\n",
    "        if self.sliding_window:\n",
    "            I = np.arange(M) + np.arange(A.shape[0] - M + 1).reshape(-1, 1)\n",
    "        else:\n",
    "            if A.shape[0]%M == 0:\n",
    "                I = np.arange(M)+np.arange(0,A.shape[0],M).reshape(-1,1)\n",
    "                \n",
    "            else:\n",
    "                I = np.arange(M)+np.arange(0,A.shape[0] -M,M).reshape(-1,1)\n",
    "            \n",
    "        B = A[I].reshape(-1, M * A.shape[1], A.shape[2])\n",
    "        ci = self.N * A.shape[1]    #Number of features per sample\n",
    "        return B[:, :ci], B[:, ci:] #Sample matrix, Target matrix\n",
    "\n",
    "#data file path\n",
    "dfp = 'data/ethereum2016to2021.csv'\n",
    "\n",
    "#Columns of price data to use\n",
    "columns = ['Close']\n",
    "df = pd.read_csv(dfp)\n",
    "time_stamps = df['Timestamp']\n",
    "df = df.loc[:,columns]\n",
    "original_df = pd.read_csv(dfp).loc[:,columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the PastSampler class, we apply it on the collected data. Since the original data ranges from 0 to over 60000, data scaling is needed to allow the neural network to understand the data easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='ethereum2016to2021_close.h5'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# normalization\n",
    "for c in columns:\n",
    "    df[c] = scaler.fit_transform(df[c].values.reshape(-1,1))\n",
    "    \n",
    "#Features are input sample dimensions(channels)\n",
    "A = np.array(df)[:,None,:]\n",
    "original_A = np.array(original_df)[:,None,:]\n",
    "time_stamps = np.array(time_stamps)[:,None,None]\n",
    "\n",
    "#Make samples of temporal sequences of pricing data (channel)\n",
    "NPS, NFS = 256, 16         #Number of past and future samples\n",
    "ps = PastSampler(NPS, NFS, sliding_window=False)\n",
    "B, Y = ps.transform(A)\n",
    "input_times, output_times = ps.transform(time_stamps)\n",
    "original_B, original_Y = ps.transform(original_A)\n",
    "\n",
    "import h5py\n",
    "with h5py.File(file_name, 'w') as f:\n",
    "    f.create_dataset(\"inputs\", data = B)\n",
    "    f.create_dataset('outputs', data = Y)\n",
    "    f.create_dataset(\"input_times\", data = input_times)\n",
    "    f.create_dataset('output_times', data = output_times)\n",
    "    f.create_dataset(\"original_datas\", data=np.array(original_df))\n",
    "    f.create_dataset('original_inputs',data=original_B)\n",
    "    f.create_dataset('original_outputs',data=original_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
